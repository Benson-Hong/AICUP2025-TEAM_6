# -*- coding: utf-8 -*-
"""ã€Œç«¶è³½ä»»å‹™2ç¨‹å¼ç¢¼ã€gitä¸Šå‚³

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JP3G5jly4hTfLWVrlADfmnPr-yb6ZbSk
"""

from huggingface_hub import login
# è²¼ä¸Šæ‚¨å‰›å‰›è¤‡è£½çš„ Hugging Face token YOUR_HUGGING_FACE_TOKEN
# ç³»çµ±æœƒæç¤ºæ‚¨è¼¸å…¥ tokenï¼Œæˆ–æ‚¨å¯ä»¥ç›´æ¥å°‡ token æ”¾åœ¨å¼•è™Ÿå…§
login(token=" YOUR_HUGGING_FACE_TOKEN") # å°‡ YOUR_HUGGING_FACE_TOKEN æ›¿æ›ç‚ºæ‚¨è¤‡è£½çš„ token
print("Hugging Face ç™»å…¥æˆåŠŸï¼")

# --- æ­¥é©Ÿ 1: æ›è¼‰ Google Drive ---
# é€™æ˜¯ç‚ºäº†è®“ Colab èƒ½å¤ å­˜å–æ‚¨é›²ç«¯ç¡¬ç¢Ÿä¸­çš„æª”æ¡ˆ
from google.colab import drive
print("æ­£åœ¨æ›è¼‰ Google Drive...")
drive.mount('/content/drive')
print("Google Drive æ›è¼‰å®Œæˆã€‚")

# --- 2025/06/07 æ–°å¢: Hugging Face ç™»å…¥å€å¡Š (é‡å°éƒ¨åˆ†å—é™æ¨¡å‹) ---
from huggingface_hub import login
# Qwen æ¨¡å‹å¯èƒ½éœ€è¦ Hugging Face Tokenã€‚
# ç‚ºäº†é¿å…åœ¨å…¬é–‹ç­†è¨˜æœ¬ä¸­æš´éœ² tokenï¼Œæ‚¨å¯ä»¥é‹è¡Œä¸€æ¬¡ `from huggingface_hub import notebook_login; notebook_login()`
# æˆ–è€…å¾ Colab çš„å·¦å´é¢æ¿é¸æ“‡ã€ŒSecretsã€(ğŸ”‘) æ¨™ç±¤ï¼Œæ·»åŠ ä¸€å€‹åç‚º `HF_TOKEN` çš„ secretï¼Œä¸¦å°‡æ‚¨çš„ token å€¼å¡«å…¥å…¶ä¸­ã€‚
try:
    login() # å˜—è©¦å¾ç’°å¢ƒè®Šæ•¸æˆ–äº¤äº’å¼ç™»å…¥
    print("Hugging Face ç™»å…¥æˆåŠŸï¼")
except Exception as e:
    print(f"Hugging Face ç™»å…¥å¤±æ•—: {e}. éƒ¨åˆ†æ¨¡å‹å¯èƒ½ç„¡æ³•è¼‰å…¥ã€‚è«‹ç¢ºèªæ‚¨çš„ token å·²è¨­ç½®ã€‚")

# --- æ­¥é©Ÿ 2: æ¸¬è©¦ PyTorch èˆ‡ CUDA ç’°å¢ƒ ---
import torch
print("\n--- PyTorch ç’°å¢ƒæª¢æŸ¥ ---")
print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
print(f"CUDA æ˜¯å¦å¯ç”¨: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA è¨­å‚™åç¨±: {torch.cuda.get_device_name(0)}")
else:
    print("è­¦å‘Š: CUDA ä¸å¯ç”¨ï¼Œæ¨¡å‹å°‡åœ¨ CPU ä¸Šé‹è¡Œï¼Œé€Ÿåº¦æœƒè¼ƒæ…¢ã€‚")

# --- æ­¥é©Ÿ 3: å®‰è£å¿…è¦çš„å‡½å¼åº« (å¼·åˆ¶å®‰è£æœ€æ–°é–‹ç™¼ç‰ˆ transformers å’Œ bitsandbytes) ---
print("\n--- å®‰è£å¿…è¦çš„å‡½å¼åº« ---")
# transformers, bitsandbytes, accelerate æ˜¯ LLM é‡åŒ–è¼‰å…¥æ‰€å¿…éœ€çš„
# datasets å’Œ openai-whisper ç”¨æ–¼è³‡æ–™è™•ç† and ASR
# *** é—œéµä¿®æ”¹ï¼šç¢ºä¿ bitsandbytes å’Œ accelerate ä¹Ÿè¢«å®‰è£ï¼Œä»¥åŠæœ€æ–° transformers ***
!pip install -q bitsandbytes accelerate
!pip install -q git+https://github.com/huggingface/huggingface_hub # ç¢ºä¿huggingface_hubæ˜¯æœ€æ–°çš„
!pip install -q git+https://github.com/huggingface/transformers.git # å˜—è©¦æœ€æ–°é–‹ç™¼ç‰ˆ
!pip install -q datasets openai-whisper
print("å‡½å¼åº«å®‰è£å®Œæˆã€‚")

# --- æ­¥é©Ÿ 4: è¼‰å…¥ LLM æ¨¡å‹ Qwen/Qwen1.5-7B-Chat (8-bit é‡åŒ–) ---
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
import torch

# --- æ›´æ›ç‚º Qwen/Qwen1.5-7B-Chat æ¨¡å‹ ---
model_name = 'Qwen/Qwen1.5-7B-Chat' # <--- é—œéµä¿®æ”¹ï¼šæ¨¡å‹åç¨±å·²ä¿®æ­£ï¼

print(f"\n--- æ­£åœ¨è¼‰å…¥ LLM æ¨¡å‹: {model_name} (8-bit é‡åŒ–) ---")

tokenizer = AutoTokenizer.from_pretrained(model_name)

# --- æ–°å¢: è™•ç† tokenizer çš„ pad_token ---
# Qwen é€šå¸¸æœ‰ pad_token_id
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token # Qwen çš„ EOS token é€šå¸¸ç‚º <|endoftext|> æˆ– <|im_end|>
    print(f"Tokenizer çš„ pad_token å·²è¨­ç½®ç‚º eos_token: {tokenizer.eos_token}")

# ä½¿ç”¨ BitsAndBytesConfig é€²è¡Œ 8-bit é‡åŒ–è¼‰å…¥
bnb_config = BitsAndBytesConfig(
    load_in_8bit=True, # è¼‰å…¥ 8-bit é‡åŒ–æ¨¡å‹
    # bnb_8bit_compute_dtype=torch.float16, # 8-bit é»˜èªä½¿ç”¨ float16 é€²è¡Œè¨ˆç®—ï¼Œå¯çœç•¥
)

# ä½¿ç”¨ from_pretrained è¼‰å…¥æ¨¡å‹ (ç§»é™¤ pipeline ç›¸é—œé‚è¼¯)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=bnb_config, # ä½¿ç”¨é‡åŒ–é…ç½®åƒæ•¸
    torch_dtype=torch.float16, # 8-bit é‡åŒ–é€šå¸¸é…åˆ float16
    device_map="auto", # è‡ªå‹•åˆ†é…è¨­å‚™
    trust_remote_code=True # Qwen æ¨¡å‹å¯èƒ½éœ€è¦è¨­ç½®ç‚º True
)

# ç¢ºä¿æ¨¡å‹çš„ pad_token_id ä¹Ÿè¢«è¨­ç½® (å¦‚æœæ¨¡å‹ config ä¸­æ²’æœ‰ï¼Œå‰‡å¾ tokenizer ç²å–)
if model.config.pad_token_id is None:
    model.config.pad_token_id = tokenizer.pad_token_id
    print(f"æ¨¡å‹é…ç½®çš„ pad_token_id å·²è¨­ç½®ç‚º Tokenizer çš„ pad_token_id: {tokenizer.pad_token_id}")

print(f"LLM æ¨¡å‹ {model_name} è¼‰å…¥å®Œæˆã€‚")

# --- æ­¥é©Ÿ 5: è¼‰å…¥ Whisper æ¨¡å‹ (æ›´æ›ç‚º 'small' æé«˜æº–ç¢ºåº¦) ---
import whisper
import torch

print("\n--- æ­£åœ¨è¼‰å…¥ Whisper æ¨¡å‹ ---")
# æ ¹æ“šæ‚¨çš„éœ€æ±‚é¸æ“‡ 'base' æˆ– 'small'ã€‚'small' æ•ˆæœæ›´å¥½ï¼Œä½† 'base' æ›´å¿«ã€‚
# å¦‚æœè¨˜æ†¶é«”è¶³å¤ ï¼Œæ¨è–¦ä½¿ç”¨ 'small' (é€šå¸¸ T4 GPU è¶³å¤ )
WHISPER_MODEL_SIZE = "small" # <--- å»ºè­°å¾ "tiny" æ”¹ç‚º "small" ä»¥æé«˜æº–ç¢ºåº¦

whisper_model_for_transcription = whisper.load_model(WHISPER_MODEL_SIZE, device="cuda" if torch.cuda.is_available() else "cpu")
print(f"Whisper æ¨¡å‹ ({WHISPER_MODEL_SIZE}) è¼‰å…¥å®Œæˆã€‚")
print(f"è¼‰å…¥çš„ Whisper æ¨¡å‹é¡å‹: {type(whisper_model_for_transcription)}")

# --- æ­¥é©Ÿ 6: è§£å£“ç¸® Private Dataset åˆ° Colab è‡¨æ™‚ç›®éŒ„ (å¸¶å¯†ç¢¼) ---
import os
import zipfile
import shutil
from datasets import Audio, Dataset, Features, Value # ä¹Ÿåœ¨æ­¤è™•å¼•å…¥ï¼Œç¢ºä¿æ‰€æœ‰å¿…è¦å‡½å¼åº«åœ¨åŒä¸€å€å¡Š

# åŸå§‹çš„ .zip æª”æ¡ˆåœ¨ Google Drive ä¸Šçš„è·¯å¾‘
google_drive_zip_path = "/content/drive/MyDrive/private dataset/Private dataset.zip"

# Colab å…§éƒ¨ç”¨æ–¼è§£å£“ç¸®çš„è‡¨æ™‚ç›®æ¨™è³‡æ–™å¤¾
colab_temp_extracted_private_dir = "/content/private_dataset_unzipped/"

# *** æ‚¨çš„å¯†ç¢¼å·²åœ¨æ­¤è™•è¨­å®šï¼ ***
# è«‹æ³¨æ„ï¼šzipfile æ¨¡çµ„è¦æ±‚å¯†ç¢¼ç‚º bytes å‹æ…‹ï¼Œæ‰€ä»¥å‰é¢æœ‰ b'
zip_password = b'aicup20660205'

print(f"\n--- æ­£åœ¨å¾ Google Drive è§£å£“ç¸®ç§äººè³‡æ–™é›†è‡³ Colab è‡¨æ™‚ç›®éŒ„ (ä½¿ç”¨å¯†ç¢¼) ---")
print(f"æª¢æŸ¥å£“ç¸®æª”: {google_drive_zip_path}")

# --- æ–°å¢çš„è§£å£“ç¸®æª¢æŸ¥åŠŸèƒ½ ---
if os.path.exists(colab_temp_extracted_private_dir) and os.listdir(colab_temp_extracted_private_dir):
    print(f"ç›®æ¨™ç›®éŒ„ '{colab_temp_extracted_private_dir}' å·²å­˜åœ¨ä¸”ä¸ç‚ºç©ºï¼Œè·³éè§£å£“ç¸®ã€‚")
    # å¦‚æœå·²ç¶“è§£å£“ç¸®ï¼Œæˆ‘å€‘ä»ç„¶éœ€è¦ç¢ºèª audio_dir çš„è·¯å¾‘
    final_audio_dir_candidate = None
    for item in os.listdir(colab_temp_extracted_private_dir):
        full_path = os.path.join(colab_temp_extracted_private_dir, item)
        if os.path.isdir(full_path) and item.lower() == "private":
            final_audio_dir_candidate = full_path
            break
        elif os.path.isdir(full_path) and os.path.exists(os.path.join(full_path, "private")):
            final_audio_dir_candidate = os.path.join(full_path, "private")
            break

    if final_audio_dir_candidate and os.path.exists(final_audio_dir_candidate):
        private_dataset_audio_dir = final_audio_dir_candidate # <--- è¨­å®šé€™å€‹è®Šæ•¸
        print(f"**ç¢ºèªç§äººè³‡æ–™é›†éŸ³è¨Šæª”å¯¦éš›è·¯å¾‘ç‚º: {private_dataset_audio_dir}**")
    else:
        print("\nè­¦å‘Š: ç›®éŒ„å·²å­˜åœ¨ï¼Œä½†ç„¡æ³•è‡ªå‹•ç¢ºèª 'private' éŸ³è¨Šè³‡æ–™å¤¾çš„æœ€çµ‚è·¯å¾‘ã€‚")
        print("è«‹æ ¹æ“šä¸Šé¢åˆ—å‡ºçš„ç›®éŒ„å…§å®¹ï¼Œæ‰‹å‹•æª¢æŸ¥ Colab å·¦å´æ–‡ä»¶ç€è¦½å™¨ï¼Œæ‰¾åˆ°æ­£ç¢ºçš„è·¯å¾‘ä¸¦è¨­å®š 'private_dataset_audio_dir'ã€‚")
        # å¦‚æœç„¡æ³•ç¢ºèªè·¯å¾‘ï¼Œå‰‡æš«æ™‚è¨­ç‚º None æˆ–è®“å¾ŒçºŒç¨‹å¼ç¢¼å ±éŒ¯
        private_dataset_audio_dir = None
else:
    # --- åŸæœ‰çš„è§£å£“ç¸®é‚è¼¯ (åªæœ‰åœ¨ç›®æ¨™ç›®éŒ„ä¸å­˜åœ¨æˆ–ç‚ºç©ºæ™‚æ‰åŸ·è¡Œ) ---
    if not os.path.exists(google_drive_zip_path):
        print(f"éŒ¯èª¤: å£“ç¸®æª” '{google_drive_zip_path}' æœªæ‰¾åˆ°ã€‚è«‹æª¢æŸ¥ Google Drive è·¯å¾‘æ˜¯å¦æ­£ç¢ºï¼Œæˆ–æª”æ¡ˆæ˜¯å¦å­˜åœ¨ã€‚")
        raise FileNotFoundError(f"Zip file not found at {google_drive_zip_path}")
    else:
        print(f"æ‰¾åˆ°å£“ç¸®æª”ï¼Œæ­£åœ¨è§£å£“ç¸®è‡³: {colab_temp_extracted_private_dir}")
        try:
            # æ¸…ç†èˆŠçš„è‡¨æ™‚è§£å£“ç¸®ç›®éŒ„ (å¦‚æœå­˜åœ¨)ï¼Œç¢ºä¿æ¯æ¬¡åŸ·è¡Œéƒ½æ˜¯æ–°çš„ç‹€æ…‹
            if os.path.exists(colab_temp_extracted_private_dir):
                shutil.rmtree(colab_temp_extracted_private_dir)
                print(f"å·²æ¸…ç†èˆŠçš„è‡¨æ™‚ç›®éŒ„: {colab_temp_extracted_private_dir}")

            # å‰µå»ºæ–°çš„è‡¨æ™‚è§£å£“ç¸®ç›®éŒ„
            os.makedirs(colab_temp_extracted_private_dir, exist_ok=True)

            with zipfile.ZipFile(google_drive_zip_path, 'r') as zip_ref:
                zip_ref.extractall(colab_temp_extracted_private_dir, pwd=zip_password)
            print("è§£å£“ç¸®å®Œæˆï¼")

            print("\nColab è‡¨æ™‚è§£å£“ç¸®ç›®éŒ„å…§å®¹ (ä¾›æ‚¨ç¢ºèªçµæ§‹):")
            final_audio_dir_candidate = None
            for item in os.listdir(colab_temp_extracted_private_dir):
                full_path = os.path.join(colab_temp_extracted_private_dir, item)
                print(f"- {item} (æ˜¯è³‡æ–™å¤¾: {os.path.isdir(full_path)})")
                if os.path.isdir(full_path) and item.lower() == "private":
                    final_audio_dir_candidate = full_path
                    break
                elif os.path.isdir(full_path) and os.path.exists(os.path.join(full_path, "private")):
                    final_audio_dir_candidate = os.path.join(full_path, "private")
                    break

            if final_audio_dir_candidate and os.path.exists(final_audio_dir_candidate):
                private_dataset_audio_dir = final_audio_dir_candidate # <--- è¨­å®šé€™å€‹è®Šæ•¸
                print(f"\n**ç¢ºèªç§äººè³‡æ–™é›†éŸ³è¨Šæª”å¯¦éš›è·¯å¾‘ç‚º: {private_dataset_audio_dir}**")
            else:
                print("\nè­¦å‘Š: ç„¡æ³•è‡ªå‹•ç¢ºèª 'private' éŸ³è¨Šè³‡æ–™å¤¾çš„æœ€çµ‚è·¯å¾‘ã€‚")
                print("è«‹æ ¹æ“šä¸Šé¢åˆ—å‡ºçš„ç›®éŒ„å…§å®¹ï¼Œæ‰‹å‹•æª¢æŸ¥ Colab å·¦å´æ–‡ä»¶ç€è¦½å™¨ï¼Œæ‰¾åˆ°æ­£ç¢ºçš„è·¯å¾‘ä¸¦è¨­å®š 'private_dataset_audio_dir'ã€‚")
                private_dataset_audio_dir = None

        except zipfile.BadZipFile:
            print(f"éŒ¯èª¤: å£“ç¸®æª” '{google_drive_zip_path}' ä¸æ˜¯æœ‰æ•ˆçš„ Zip æª”æ¡ˆã€‚")
            raise
        except RuntimeError as e:
            print(f"è§£å£“ç¸®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            print("é€™é€šå¸¸è¡¨ç¤ºå¯†ç¢¼ä¸æ­£ç¢ºï¼Œæˆ–è€…å£“ç¸®æª”ç¢ºå¯¦æ˜¯åŠ å¯†çš„ã€‚")
            raise
        except Exception as e:
            print(f"è§£å£“ç¸®æ™‚ç™¼ç”Ÿå…¶ä»–éŒ¯èª¤: {e}")
            raise

# --- è·¯å¾‘é…ç½® ---
# ç¢ºä¿ private_dataset_audio_dir å·²ç¶“è¢«è¨­å®š
if private_dataset_audio_dir is None:
    raise FileNotFoundError("ç§äººè³‡æ–™é›†éŸ³è¨Šç›®éŒ„æœªæ­£ç¢ºè¨­å®šã€‚ç„¡æ³•ç¹¼çºŒã€‚")

task1_private_answer_path = '/content/task1_answer.txt'
task2_private_output_dir = '/content/drive/MyDrive/AICUP_Results_Private_Dataset/'
task2_private_output_path = os.path.join(task2_private_output_dir, 'task2_private_answer.txt')

print("\n--- è·¯å¾‘é…ç½® ---")
print(f"ç§äººè³‡æ–™é›†éŸ³è¨Šç›®éŒ„ (Colab è‡¨æ™‚): {private_dataset_audio_dir}")
print(f"ç§äººè³‡æ–™é›† Task 1 ç­”æ¡ˆè·¯å¾‘ (Colab è‡¨æ™‚): {task1_private_answer_path}")
print(f"ç§äººè³‡æ–™é›† Task 2 è¼¸å‡ºè·¯å¾‘ (Google Drive): {task2_private_output_path}")

# ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
os.makedirs(task2_private_output_dir, exist_ok=True)

# --- æ­£åœ¨è¼‰å…¥ç§äººæ¸¬è©¦è³‡æ–™é›†éŸ³è¨Šæª” ---
print("\n--- æ­£åœ¨è¼‰å…¥ç§äººæ¸¬è©¦è³‡æ–™é›†éŸ³è¨Šæª” ---")
audio_files = []
if os.path.exists(private_dataset_audio_dir):
    for filename in sorted(os.listdir(private_dataset_audio_dir)):
        if filename.endswith(".wav") or filename.endswith(".flac"):
            audio_id = os.path.splitext(filename)[0]
            audio_files.append({"audio_id": audio_id, "audio": os.path.join(private_dataset_audio_dir, filename)})
else:
    print(f"éŒ¯èª¤: ç§äººè³‡æ–™é›†éŸ³è¨Šç›®éŒ„ '{private_dataset_audio_dir}' ä¸å­˜åœ¨ã€‚è«‹ç¢ºèªè§£å£“ç¸®æ­¥é©ŸæˆåŠŸä¸”è·¯å¾‘æ­£ç¢ºã€‚")
    raise FileNotFoundError(f"Audio directory not found at {private_dataset_audio_dir}")

features = Features({
    "audio_id": Value("string"),
    "audio": Audio(sampling_rate=16000)
})
private_validation_dataset = Dataset.from_list(audio_files, features=features)
print(f"å·²è¼‰å…¥ {len(private_validation_dataset)} å€‹ç§äººæ¸¬è©¦è³‡æ–™é›†éŸ³è¨Šæª”æ¡ˆã€‚")

# --- æ­£åœ¨å¾ Task 1 æª”æ¡ˆ (/content/task1_answer.txt) è®€å–è½‰éŒ„æ–‡å­— ---
transcriptions = {}
try:
    with open(task1_private_answer_path, "r", encoding="utf-8") as f:
        for line in f:
            if "\t" in line:
                audio_id, text = line.strip().split("\t", 1)
                transcriptions[audio_id] = text
    print(f"å·²å¾ Task 1 æª”æ¡ˆ ({task1_private_answer_path}) è®€å– {len(transcriptions)} å€‹è½‰éŒ„æ–‡å­—ã€‚")
except FileNotFoundError:
    print(f"éŒ¯èª¤: ç§äºº Task 1 è¼¸å‡ºæª”æ¡ˆ ({task1_private_answer_path}) æœªæ‰¾åˆ°ã€‚è«‹ç¢ºèªæ‚¨å·²å°‡ 'task1_answer.txt' ä¸Šå‚³è‡³ Colab çš„ /content/ ç›®éŒ„ï¼Œæˆ–å…ˆå®Œæˆæ‰€æœ‰æª”æ¡ˆçš„ Task 1 è™•ç†ã€‚")
    raise FileNotFoundError(f"Private Task 1 output file not found at {task1_private_answer_path}.")
except Exception as e:
    print(f"è®€å–ç§äºº Task 1 è¼¸å‡ºæª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    transcriptions = {}
    raise # é‡æ–°æ‹‹å‡ºç•°å¸¸ï¼Œè®“å•é¡Œæ›´æ˜é¡¯

# --- æ­¥é©Ÿ 10: å¾ LLM çš„è¼¸å‡ºä¸­æå– JSON å…§å®¹çš„è¼”åŠ©å‡½å¼ ---
# é€™å€‹å‡½å¼ç”¨æ–¼å¾ LLM çš„è‡ªç”±æ–‡æœ¬è¼¸å‡ºä¸­ç²¾ç¢ºæå– JSON çµæ§‹
import re
import json
import time
import os

def extract_json_from_output(generated_text):
    """
    ä½¿ç”¨æ­£å‰‡è¡¨é”å¼å¾ LLM çš„è¼¸å‡ºä¸­æå– JSON å…§å®¹ã€‚
    æœƒå„ªå…ˆå°‹æ‰¾ ```json å€å¡Šï¼Œå¦‚æœæ²’æœ‰æ‰¾åˆ°ï¼Œæœƒå˜—è©¦å°‹æ‰¾ {} åŒ…è£¹çš„å…§å®¹ä½œç‚ºå‚™ç”¨ã€‚
    """
    json_match = re.search(r'```json\s*(.*?)\s*```', generated_text, re.DOTALL)
    if json_match:
        json_content = json_match.group(1).strip()
        if json_content:
            try:
                json.loads(json_content)
                print("     (ä½¿ç”¨ä¸»è¦æ–¹æ³•æˆåŠŸæå–ä¸¦é©—è­‰ JSON)")
                return json_content
            except json.JSONDecodeError:
                print(f"     (ä¸»è¦æ–¹æ³•æå–åˆ°å…§å®¹ä½† JSON ç„¡æ•ˆæˆ–ä¸å®Œæ•´: {json_content[:200]}...)")
                # å˜—è©¦æ¸…ç†ä¸å®Œæ•´çš„ JSONï¼Œåªä¿ç•™æœ€å¤–å±¤ {} ä¹‹é–“çš„å…§å®¹
                clean_content = re.sub(r'(.*?)\s*```.*', r'\1', json_content, flags=re.DOTALL).strip()
                try:
                    json.loads(clean_content)
                    print(f"     (ä¸»è¦æ–¹æ³•æ¸…ç†å¾ŒæˆåŠŸæå–ä¸¦é©—è­‰ JSON)")
                    return clean_content
                except json.JSONDecodeError:
                    print(f"     (ä¸»è¦æ–¹æ³•æ¸…ç†å¾Œ JSON ä»ç„¡æ•ˆ: {clean_content[:200]}...)")
                    pass

    all_json_candidates = []
    # å°‹æ‰¾æ‰€æœ‰å¯èƒ½è¢«å¤§æ‹¬è™Ÿ {} åŒ…è£¹çš„å…§å®¹ (åµŒå¥—çš„ä¹Ÿè€ƒæ…®)
    # é€™å€‹æ­£å‰‡è¡¨é”å¼ (?R) æ˜¯éæ­¸åŒ¹é…çš„é—œéµï¼Œå®ƒæœƒåŒ¹é…åµŒå¥—çš„ {}
    for match_content in re.findall(r'\{(?:[^{}]|(?R))*\}+', generated_text, re.DOTALL):
        try:
            json.loads(match_content)
            all_json_candidates.append(match_content)
        except json.JSONDecodeError:
            pass

    if all_json_candidates:
        # å¦‚æœæœ‰å¤šå€‹ JSON å€™é¸ï¼Œé¸æ“‡æœ€é•·çš„ä¸€å€‹
        fallback_content = max(all_json_candidates, key=len)
        print("     (ä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆæå–åˆ°å¯èƒ½çš„ JSON)")
        return fallback_content

    print("     (æœªæ‰¾åˆ°å¯æå–çš„ JSON å…§å®¹)")
    return None

# --- æ­¥é©Ÿ 11: é–‹å§‹è™•ç†ç§äººè³‡æ–™é›†ä»¥ç”Ÿæˆ Task 2 æäº¤æª”æ¡ˆ (é‡æ–°ç”Ÿæˆæ¨¡å¼) ---
print("\n--- æ­£åœ¨è™•ç†ç§äººè³‡æ–™é›†ä»¥ç”Ÿæˆ Task 2 æäº¤æª”æ¡ˆ (é‡æ–°ç”Ÿæˆæ‰€æœ‰çµæœ) ---")

# --- ä¸»è¦è™•ç†é‚è¼¯ ---
if len(private_validation_dataset) == 0:
    print("éŒ¯èª¤: ç§äººæ¸¬è©¦è³‡æ–™é›†ç‚ºç©ºï¼Œç„¡æ³•é€²è¡Œ Task 2 è™•ç†ã€‚")
elif len(transcriptions) == 0:
    print("éŒ¯èª¤: ç§äºº Task 1 è½‰éŒ„æ•¸æ“šç‚ºç©ºï¼Œç„¡æ³•é€²è¡Œ Task 2 è™•ç†ã€‚")
else:
    print(f"ç¸½å…±æœ‰ {len(private_validation_dataset)} å€‹æª”æ¡ˆéœ€è¦è™•ç† Task 2ã€‚")
    print("å°‡å¾é ­é–‹å§‹è™•ç†æ‰€æœ‰æª”æ¡ˆï¼Œçµæœå°‡å¯«å…¥æ–°æª”æ¡ˆã€‚") # é€™æ¬¡é¸æ“‡å®Œå…¨é‡æ–°ç”Ÿæˆï¼Œä¸è€ƒæ…®æ–·é»çºŒå‚³

    if 'whisper_model_for_transcription' not in locals() or whisper_model_for_transcription is None:
        print("éŒ¯èª¤: æ‰¾ä¸åˆ° Whisper æ¨¡å‹è®Šæ•¸ 'whisper_model_for_transcription'ã€‚è«‹ç¢ºèªè¼‰å…¥æ¨¡å‹çš„ç¨ç«‹å„²å­˜æ ¼å·²æˆåŠŸåŸ·è¡Œã€‚ç„¡æ³•é€²è¡Œ Task 2 è™•ç†ã€‚")
        print("è«‹æª¢æŸ¥ä¸¦é‡æ–°åŸ·è¡Œ Whisper æ¨¡å‹è¼‰å…¥çš„ç¨‹å¼ç¢¼å€å¡Šã€‚")
    elif 'model' not in locals() or model is None or 'tokenizer' not in locals() or tokenizer is None:
        print("éŒ¯èª¤: æ‰¾ä¸åˆ° LLM æ¨¡å‹æˆ– Tokenizer è®Šæ•¸ã€‚è«‹ç¢ºèªè¼‰å…¥ LLM çš„å„²å­˜æ ¼å·²æˆåŠŸåŸ·è¡Œã€‚ç„¡æ³•é€²è¡Œ Task 2 æ¨è«–ã€‚")
        print("è«‹æª¢æŸ¥ä¸¦é‡æ–°åŸ·è¡Œ LLM æ¨¡å‹è¼‰å…¥çš„ç¨‹å¼ç¢¼å€å¡Šã€‚")
    else:
        print("æ­£åœ¨å»ºç«‹æŒ‰ç…§ audio_id æ’åºçš„æª”æ¡ˆåˆ—è¡¨ç”¨æ–¼è™•ç†...")
        try:
            sorted_audio_ids_with_indices = sorted(
                [(data['audio_id'], i) for i, data in enumerate(private_validation_dataset)],
                key=lambda item: item[0]
            )
            print(f"å·²å»ºç«‹åŒ…å« {len(sorted_audio_ids_with_indices)} å€‹æª”æ¡ˆçš„æ’åºåˆ—è¡¨ã€‚")
        except Exception as e:
            print(f"å»ºç«‹æ’åºæª”æ¡ˆåˆ—è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}ï¼Œç„¡æ³•æŒ‰æ’åºé †åºè™•ç†ã€‚")
            raise e

        # *** æ–°å¢çš„è·³éæª”æ¡ˆè¨­å®š ***
        # è¨­å®šæ‚¨å¸Œæœ›å¾ç¬¬å¹¾å€‹æª”æ¡ˆé–‹å§‹è™•ç† (ä¾‹å¦‚ï¼Œ99è¡¨ç¤ºå¾ç´¢å¼•99é–‹å§‹ï¼Œå³æ’åºå¾Œçš„ç¬¬100å€‹æª”æ¡ˆ)
        START_INDEX = 99
        print(f"å°‡è·³éå‰ {START_INDEX} å€‹æª”æ¡ˆï¼Œå¾æ’åºåˆ—è¡¨ä¸­çš„ç¬¬ {START_INDEX + 1} å€‹æª”æ¡ˆé–‹å§‹è™•ç†ã€‚")

        # ä»¥å¯«å…¥æ¨¡å¼ ('w') æ‰“é–‹ Task 2 è¼¸å‡ºæª”æ¡ˆï¼Œæ¯æ¬¡é‹è¡Œéƒ½å‰µå»ºæ–°æª”æ¡ˆ
        with open(task2_private_output_path, "w", encoding="utf-8") as task2_file:
            start_time = time.time()
            processed_this_run = 0

            for sorted_i, (audio_id, original_i) in enumerate(sorted_audio_ids_with_indices):
                # *** æ–°å¢çš„è·³éé‚è¼¯ ***
                if sorted_i < START_INDEX:
                    print(f"--- è·³éæª”æ¡ˆ ID: {audio_id} (åœ¨æ’åºåˆ—è¡¨ä¸­çš„ä½ç½®: {sorted_i+1}/{len(private_validation_dataset)}) ---")
                    continue # è·³éç•¶å‰æª”æ¡ˆï¼Œç¹¼çºŒä¸‹ä¸€å€‹

                data = private_validation_dataset[original_i]
                audio_path = data["audio"]["path"]
                transcription_text_from_task1 = transcriptions.get(audio_id)

                if transcription_text_from_task1 is None:
                    print(f"è­¦å‘Š: æœªåœ¨ Task 1 è½‰éŒ„ä¸­æ‰¾åˆ°æª”æ¡ˆ ID: {audio_id} çš„æ–‡å­—ã€‚è·³é Task 2 è™•ç†ã€‚")
                    continue

                print(f"\n--- æ­£åœ¨è™•ç†æª”æ¡ˆ ID: {audio_id} (åœ¨æ’åºåˆ—è¡¨ä¸­çš„ä½ç½®: {sorted_i+1}/{len(private_validation_dataset)}) --- (Task 2)")

                try:
                    print("     æ­£åœ¨é‡æ–°é‹è¡Œ ASR ä»¥ç²å–æ™‚é–“æˆ³è¨˜...")
                    asr_result_for_timestamps = whisper_model_for_transcription.transcribe(
                        audio_path, fp16=False, word_timestamps=True
                    )
                    word_timestamps = asr_result_for_timestamps.get("segments", [])

                    print("     æ­£åœ¨ä½¿ç”¨ LLM é€²è¡Œæ•æ„Ÿè³‡è¨Šè¾¨è­˜...")
                    transcription_text_for_llm = transcription_text_from_task1

                    # é€™è£¡å®šç¾©æ‰€æœ‰å¯èƒ½çš„æ•æ„Ÿä¿¡æ¯é¡åˆ¥
                    all_shi_categories = [
                        "PATIENT", "DOCTOR", "USERNAME", "PERSONALNAME", "FAMILYNAME",
                        "PROFESSION", "ROOM", "DEPARTMENT", "HOSPITAL", "ORGANIZATION",
                        "STREET", "CITY", "STATE", "COUNTRY", "COUNTY", "ZIP", "LOCATION-OTHER",
                        "DISTRICT", "AGE", "DATE", "TIME", "DURATION", "SET", "PHONE", "FAX",
                        "EMAIL", "URL", "IPADDRESS", "OTHER", "SOCIAL_SECURITY_NUMBER",
                        "MEDICAL_RECORD_NUMBER", "HEALTH_PLAN_NUMBER", "ACCOUNT_NUMBER",
                        "LICENSE_NUMBER", "VEHICLE_ID", "DEVICE_ID", "BIOMETRIC_ID", "ID_NUMBER"
                    ]
                    # æ§‹å»º JSON æ ¼å¼æ¨¡æ¿ï¼ŒåŒ…å«æ‰€æœ‰é¡åˆ¥
                    json_format_template = "{\n     \"text\": \"{transcription_text_for_llm}\","
                    for cat in all_shi_categories:
                        json_format_template += f"\n     \"{cat}\": [\"list all extracted {cat} here\"],"
                    json_format_template = json_format_template.rstrip(',') + "\n}" # ç§»é™¤æœ€å¾Œä¸€å€‹é€—è™Ÿï¼Œä¸¦çµæŸ JSON

                    # --- LLM æç¤ºè© (Messages æ ¼å¼ï¼Œé©åˆ Qwen å’Œå…¶ä»– Chat æ¨¡å‹) ---
                    messages = [
                        {"role": "system", "content": "You are an expert in extracting sensitive health information. Your ONLY task is to return a valid JSON object. Do NOT include any other text, explanations, or code outside the JSON block. Ensure the JSON is well-formed and follows the specified schema. If a category has no corresponding information found in the text, its list in the JSON should be empty []."},
                        {"role": "user", "content": f'''Extract Sensitive Health Information (SHI) from the following text.
The text is a transcription of a doctor-patient conversation.

Identify and categorize the SHI into the following specific categories:
{', '.join(all_shi_categories)}.

Return ONLY the extracted SHI in a single JSON object. The JSON object MUST be enclosed within ```json and ``` blocks.
The JSON object must strictly follow this structure:
```json
{json_format_template}
Extract ONLY information that is explicitly mentioned in the text.

Here is the text: "{transcription_text_for_llm}"
'''
                        }
                    ]

                    # --- LLM å‘¼å«æ–¹å¼ï¼šä½¿ç”¨ model.generate é‡æ–°å•Ÿç”¨ KV Cache ---
                    # æ‡‰ç”¨èŠå¤©æ¨¡æ¿ä¸¦åˆ†è©
                    chat_template_output = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True)

                    input_ids = torch.tensor([chat_template_output]).to(model.device)
                    attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=model.device)

                    output_tokens = model.generate(
                        input_ids,
                        attention_mask=attention_mask,
                        max_new_tokens=1024, # å¢åŠ æœ€å¤§ç”Ÿæˆ token æ•¸é‡ä»¥ç¢ºä¿å®Œæ•´ JSON è¼¸å‡º
                        do_sample=False, # ä¸é€²è¡Œæ¡æ¨£ï¼Œè¼¸å‡ºç¢ºå®šæ€§è¼ƒé«˜
                        pad_token_id=tokenizer.pad_token_id,
                        eos_token_id=tokenizer.eos_token_id,
                        use_cache=True # <--- é—œéµä¿®æ”¹ï¼šé‡æ–°å•Ÿç”¨ KV Cacheï¼Œå¸Œæœ› Qwen 7B å…¼å®¹
                    )

                    # è§£ç¢¼ç”Ÿæˆçš„ token
                    generated_text = tokenizer.decode(output_tokens[0][input_ids.shape[-1]:], skip_special_tokens=True)

                    print("     LLM Generated Response (partial):", generated_text[:500].replace('\n', ' ') + "..." if len(generated_text) > 500 else generated_text.replace('\n', ' '))
                    # --- LLM å‘¼å«æ–¹å¼çµæŸ ---

                    json_content = extract_json_from_output(generated_text)

                    parsed_json = None
                    if not json_content:
                        print(f"     âŒ ç„¡æ³•å¾ LLM å›æ‡‰ä¸­æå– JSON å…§å®¹: {audio_id}")
                    else:
                        try:
                            parsed_json = json.loads(json_content)
                            print("     æˆåŠŸè§£æ LLM çš„ JSON å›æ‡‰ã€‚")
                        except json.JSONDecodeError as e:
                            print(f"     âŒ JSON è§£æéŒ¯èª¤ ({audio_id}), éŒ¯èª¤: {e}")
                            parsed_json = None

                    shi_timestamps_found = []

                    if parsed_json is not None and word_timestamps:
                        # å°‡æ‰€æœ‰å¸¶æ™‚é–“æˆ³çš„è©èªæ‰å¹³åŒ–åˆ°ä¸€å€‹åˆ—è¡¨ä¸­ï¼Œæ–¹ä¾¿éæ­·
                        all_words_with_timestamps = []
                        for seg in word_timestamps:
                            if 'words' in seg:
                                all_words_with_timestamps.extend(seg["words"])

                        # éæ­·æ‰€æœ‰æ•æ„Ÿä¿¡æ¯é¡åˆ¥
                        for category in all_shi_categories:
                            values = parsed_json.get(category, []) # å¾è§£æçš„ JSON ä¸­ç²å–è©²é¡åˆ¥çš„å€¼åˆ—è¡¨
                            if isinstance(values, list): # ç¢ºä¿ values æ˜¯åˆ—è¡¨
                                for value_text_from_llm in values: # é€™æ˜¯ LLM æå–çš„æ•æ„Ÿè©æ–‡å­—
                                    if not value_text_from_llm or not isinstance(value_text_from_llm, str):
                                        continue # è·³éç©ºçš„æˆ–éå­—ä¸²çš„å€¼

                                    # å°‡ LLM æå–çš„æ•æ„Ÿè©çŸ­èªåˆ†è§£ç‚ºå–®è©åˆ—è¡¨ï¼Œä¸¦è½‰æ›ç‚ºå°å¯«ï¼Œå»é™¤æ¨™é»ç¬¦è™Ÿ
                                    value_words_llm = re.findall(r'\b\w+\b', value_text_from_llm.lower())
                                    if not value_words_llm:
                                        continue # å¦‚æœåˆ†è§£å¾Œæ˜¯ç©ºçš„ï¼Œå‰‡è·³é

                                    # åœ¨ Whisper è½‰éŒ„çš„è©èªåˆ—è¡¨ä¸­å°‹æ‰¾åŒ¹é…çš„é€£çºŒè©èªåºåˆ—
                                    # é€™è£¡éœ€è¦ä¸€å€‹åµŒå¥—å¾ªç’°ä¾†å¯¦ç¾å­åºåˆ—åŒ¹é…
                                    for i in range(len(all_words_with_timestamps) - len(value_words_llm) + 1):
                                        match_found = True
                                        current_match_words = [] # å„²å­˜ç•¶å‰æ½›åœ¨åŒ¹é…çš„ Whisper è©èª
                                        for j in range(len(value_words_llm)):
                                            asr_word_info = all_words_with_timestamps[i + j]
                                            # å°‡ Whisper è©èªä¹Ÿé€²è¡Œæ¸…ç†å’Œè½‰æ›ç‚ºå°å¯«
                                            asr_word_lower = re.sub(r'[^\w]', '', asr_word_info['word']).lower()

                                            # æª¢æŸ¥æ˜¯å¦åŒ¹é…
                                            if asr_word_lower != value_words_llm[j]:
                                                match_found = False
                                                break # ä¸åŒ¹é…ï¼Œè·³å‡ºå…§å±¤å¾ªç’°
                                            current_match_words.append(asr_word_info)

                                        if match_found:
                                            # å¦‚æœæ‰¾åˆ°å®Œæ•´åŒ¹é…ï¼Œæå–æ™‚é–“æˆ³å’ŒåŒ¹é…æ–‡æœ¬
                                            start_time_match = current_match_words[0]['start']
                                            end_time_match = current_match_words[-1]['end']
                                            matched_text = " ".join([w['word'] for w in current_match_words]) # ä½¿ç”¨åŸå§‹ Whisper è©èªæ§‹å»ºåŒ¹é…æ–‡æœ¬

                                            shi_timestamps_found.append({
                                                "file_id": audio_id,
                                                "category": category,
                                                "start": start_time_match,
                                                "end": end_time_match,
                                                "text": matched_text
                                            })
                                            break # æ‰¾åˆ°ä¸€å€‹åŒ¹é…å¾Œï¼Œè·³å‡ºç•¶å‰æ•æ„Ÿè©åœ¨æ‰€æœ‰ Whisper è©èªä¸­çš„å°‹æ‰¾ï¼Œè™•ç†ä¸‹ä¸€å€‹æ•æ„Ÿè©

                    # è¼¸å‡º Task 2 è‡³ task2_private_output_path
                    if shi_timestamps_found: # åªåœ¨æ‰¾åˆ°æ•æ„Ÿè©ä¸¦åŒ¹é…åˆ°æ™‚é–“æˆ³æ™‚æ‰å¯«å…¥
                        # æŒ‰ç…§æ™‚é–“æˆ³æ’åºè¼¸å‡ºï¼Œä»¥ä¾¿æ–¼è©•ä¼°
                        shi_timestamps_found.sort(key=lambda x: (x['start'], x['end']))
                        for item in shi_timestamps_found:
                            # æ ¼å¼ç‚º: Filename{TAB}SHI_type{TAB}Start{TAB}End{TAB}Text
                            # Task 2 æäº¤æ ¼å¼çš„ Time æ˜¯ç§’ï¼Œç²¾åº¦è¦æ±‚
                            task2_file.write(f"{item['file_id']}\t{item['category']}\t{item['start']:.3f}\t{item['end']:.3f}\t{item['text']}\n")

                        # ç‚ºäº†é˜²æ­¢ç¨‹å¼ä¸­æ–·æ™‚æ•¸æ“šä¸Ÿå¤±ï¼ŒåŠæ™‚å°‡ç·©è¡å€çš„æ•¸æ“šå¯«å…¥ç£ç›¤
                        task2_file.flush()
                        os.fsync(task2_file.fileno())

                        print(f"     Task 2 çµæœå·²å¯«å…¥ï¼Œæ‰¾åˆ° {len(shi_timestamps_found)} å€‹å¸¶æ™‚é–“æˆ³çš„æ•æ„Ÿè©ã€‚")
                        processed_this_run += 1
                    else:
                        print("     æ²’æœ‰æ‰¾åˆ°å¸¶æ™‚é–“æˆ³çš„æ•æ„Ÿè©ï¼ŒTask 2 æ²’æœ‰å¯«å…¥ã€‚")

                except Exception as e:
                    print(f"     è™•ç†æª”æ¡ˆ ID: {audio_id} æ™‚ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤ (Task 2): {e}")
                    # å¦‚æœè™•ç†å–®å€‹æª”æ¡ˆ Task 2 æ™‚å‡ºéŒ¯ï¼Œè¨˜éŒ„éŒ¯èª¤ä¸¦ç¹¼çºŒè™•ç†ä¸‹ä¸€å€‹æª”æ¡ˆ
                    pass # ä½¿ç”¨ pass è·³ééŒ¯èª¤è™•ç†ï¼Œç¹¼çºŒè¿´åœˆ

            # --- Task 2 è™•ç†è¿´åœˆçµæŸ ---
            # åœ¨éæ­·è¿´åœˆçµæŸå¾Œï¼Œè™•ç†å®Œæˆè¨Šæ¯
            end_time = time.time() # çµæŸè¨ˆæ™‚
            elapsed_time = end_time - start_time

            # é‡æ–°è¨ˆç®— Task 2 å·²è™•ç†æª”æ¡ˆç¸½æ•¸ (å› ç‚ºæœ¬æ¬¡é‹è¡Œæ˜¯å®Œå…¨é‡æ–°ç”Ÿæˆ)
            try:
                with open(task2_private_output_path, "r", encoding="utf-8") as f:
                    # çµ±è¨ˆæ–‡ä»¶ä¸­å”¯ä¸€çš„ audio_id æ•¸é‡
                    final_processed_count_task2 = len(set(line.strip().split('\t', 1)[0] for line in f if line.strip()))
            except FileNotFoundError:
                final_processed_count_task2 = 0

            print(f"\n=== ç§äººæ¸¬è©¦è³‡æ–™é›† Task 2 è™•ç†å®Œæˆ (æœ¬æ¬¡é‹è¡ŒæˆåŠŸè™•ç† {processed_this_run} å€‹æª”æ¡ˆçš„ Task 2) ===")
            print(f"æœ¬æ¬¡è™•ç†æ™‚é–“: {elapsed_time:.2f} ç§’")
            print(f"Task 2 çµæœå·²ä¿å­˜åˆ°: {task2_private_output_path}ï¼ŒåŒ…å« {final_processed_count_task2} å€‹æª”æ¡ˆçš„æ•¸æ“šã€‚")
            print("================================")

a